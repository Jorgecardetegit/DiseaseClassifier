{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp7jTU1WA3B97ETjiiPY4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorgecardetegit/DiseaseClassifier/blob/main/Malaria_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6c9VPSgrHzVO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, dataset_info = tfds.load('malaria', with_info=True,\n",
        "                                  as_supervised=True,\n",
        "                                  shuffle_files = True,\n",
        "                                  split=['train'])"
      ],
      "metadata": {
        "id": "E6jxFMRVIQbT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split"
      ],
      "metadata": {
        "id": "LWAeT0tW0dkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):\n",
        "  DATASET_SIZE = len(dataset)\n",
        "\n",
        "  train_dataset = dataset.take(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "\n",
        "  val_test_dataset = dataset.skip(int(TRAIN_RATIO*DATASET_SIZE))\n",
        "  val_dataset = val_test_dataset.take(int(VAL_RATIO*DATASET_SIZE))\n",
        "\n",
        "  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))\n",
        "  return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "LiO8y7orzZ0e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = splits(dataset[0], TRAIN_RATIO, VAL_RATIO, TEST_RATIO )"
      ],
      "metadata": {
        "id": "ZSsFIEBfIwt3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "qI_5p3NQ0ltA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "JNkFFZNS0p3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IM_SIZE = 224\n",
        "def resize_rescale(image, label):\n",
        "  return tf.image.resize(image, (IM_SIZE, IM_SIZE))/.255, label"
      ],
      "metadata": {
        "id": "A5MhzM4H06RR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(resize_rescale)\n",
        "val_dataset = val_dataset.map(resize_rescale)\n",
        "test_dataset = test_dataset.map(resize_rescale)\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4qgIE9V1LHk",
        "outputId": "ad16dd95-d330-4fb6-c36a-d45f94c98b94"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "y2S2ZZy-17II"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = val_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Gdxc7vyQ8DpD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (IM_SIZE, IM_SIZE, 3)),\n",
        "\n",
        "    Conv2D(filters = 6, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size = 2, strides = 2),\n",
        "\n",
        "    Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size = 2, strides = 2),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(1000, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(100, activation = \"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation = \"sigmoid\"),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "GQt7Uedi2Xrp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n-yqffk30IE",
        "outputId": "62f63077-1b20-439a-8ff9-4f6c0a32c037"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 220, 220, 6)       456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 110, 110, 6)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 106, 106, 16)      2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 53, 53, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 44944)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              44945000  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               100100    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45048073 (171.84 MB)\n",
            "Trainable params: 45048073 (171.84 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.1),\n",
        "              loss = BinaryCrossentropy(),\n",
        "              metrics = \"accuracy\")"
      ],
      "metadata": {
        "id": "HULpWuxr4kQn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data = val_dataset, epochs = 5, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh_e_Y_-58Re",
        "outputId": "09f095c0-8328-4aa6-f7c2-ce82198fdb07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "689/689 [==============================] - 1782s 3s/step - loss: 0.5285 - accuracy: 0.7514 - val_loss: 0.9764 - val_accuracy: 0.6338\n",
            "Epoch 2/5\n",
            "689/689 [==============================] - 1755s 3s/step - loss: 0.3343 - accuracy: 0.8734 - val_loss: 0.8212 - val_accuracy: 0.5525\n",
            "Epoch 3/5\n",
            "314/689 [============>.................] - ETA: 15:07 - loss: 0.2231 - accuracy: 0.9295"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train_loss\", \"val_loss\"])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YJUiyXMK0ky2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation and Testing"
      ],
      "metadata": {
        "id": "l-eA8mK0AupT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test_dataset.batch(1)"
      ],
      "metadata": {
        "id": "QjUlOHSVIwxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "LGt1ZBeHIwzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(test_dataset.take(1)[0][0])"
      ],
      "metadata": {
        "id": "yNlSBJsxBdKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parasite_or_not(x):\n",
        "  if(x<0.5):\n",
        "    return str(\"P\")\n",
        "  else:\n",
        "    return str(\"U\")"
      ],
      "metadata": {
        "id": "niQ4lgOJIw1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paraiste_or_not(model.predict(test_dataset.take(1)[0][0]))"
      ],
      "metadata": {
        "id": "Wf7-dxvjB7uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image, label) in enumerate(test_dataset.take(9)):\n",
        "\n",
        "  ax = plt.subplot(3,3, i+1)\n",
        "  plt.imshow(image[0])\n",
        "  plt.title(str(parasite_or_not(label.numpy()[0])) + \":\" + str(parasite_or_not(lente_model.predict(image)[0][0])))\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "0jrMnTjdCElx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading from Google Drive"
      ],
      "metadata": {
        "id": "0wv40ZP8Cy_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "id": "IskiRx1SCEoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/lenet /content/drive/MyDrive/lenet_colab/\n"
      ],
      "metadata": {
        "id": "1mULbqYmE0PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/lenet_colab/ /content/lenet_colab/"
      ],
      "metadata": {
        "id": "4YqR6xnFE-QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model with other ways that the Sequential API"
      ],
      "metadata": {
        "id": "KJytQRx7FisO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functional API"
      ],
      "metadata": {
        "id": "eHlKYj7hFps9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "funct_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input_image\")\n",
        "\n",
        "x = Conv2D(filters = 6, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\")(func_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D (pool_size = 2, strides = 2)(x)\n",
        "\n",
        "x = Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(pool_size = 2, strides = 2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1000, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")"
      ],
      "metadata": {
        "id": "-M9TkAEJFGpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "id": "fhC41BWgFGrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_func.compile(optimizer = Adam(learning_rate = 0.01),\n",
        "                         loss = BinaryCrossentropy(),\n",
        "                         metrics = \"accuracy\")"
      ],
      "metadata": {
        "id": "9-BbAczoFGt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lenet_model.fit(train_dataset, validation_data = val_dataset, epochs = 5, verbose = 1)"
      ],
      "metadata": {
        "id": "_OEaI1RHFGvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extractor"
      ],
      "metadata": {
        "id": "QrxJrqKwMliA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "funct_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input_image\")\n",
        "\n",
        "x = Conv2D(filters = 6, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\")(func_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D (pool_size = 2, strides = 2)(x)\n",
        "\n",
        "x = Conv2D(filters = 16, kernel_size = 5, strides = 1, padding = \"valid\", activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = MaxPool2D(pool_size = 2, strides = 2)(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "lenet_model_func = Model(func_input, output, name = \"Feature_Extractor\")"
      ],
      "metadata": {
        "id": "Ep4M5yJ6FGxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_model.summary()"
      ],
      "metadata": {
        "id": "ixTXhB1nM69n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "funct_input = Input(shape = (IM_SIZE, IM_SIZE, 3), name = \"Input_image\")\n",
        "\n",
        "x = feature_extractor_model(func_input)\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1000, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(100, activation = \"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "func_output = Dense(1, activation = \"sigmoid\")(x)\n",
        "\n",
        "lenet_model_func = Model(func_input, func_output, name = \"Lenet_Model\")"
      ],
      "metadata": {
        "id": "_oGbxw9dNBrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model_func.summary()"
      ],
      "metadata": {
        "id": "YIOsRSItNWyY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}