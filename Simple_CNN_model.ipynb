{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dhJ4DJHF4D_KlLsiKZN26zIBj-o4Fe5d",
      "authorship_tag": "ABX9TyMZpB9k3+Rr3bkm6lxdlGGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jorgecardetegit/DiseaseClassifier/blob/main/Simple_CNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZGCFe_6vNZR",
        "outputId": "53290ed5-f4b8-4018-d84a-8b01f2183c60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QyqzOVmYb7Kd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from glob import glob\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_dir = \"/content/drive/MyDrive/Apple disease proyect/dataset\"\n",
        "categories = os.listdir(gen_dir)\n",
        "categories = [category.split('___')[1].lower() for category in categories]\n",
        "\n",
        "apple_scab = glob('/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Apple_scab/*.JPG')\n",
        "black_rot = glob(\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Black_rot/*.JPG\")\n",
        "cedar_apple_rust = glob(\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Cedar_apple_rust/*.JPG\")\n",
        "healthy = glob(\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___healthy/*.JPG\")"
      ],
      "metadata": {
        "id": "opsMMf-c2rdS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Preprocessing\n",
        "\n",
        "### Normalizing or Standardizing and rescaling\n",
        "\n",
        "All the images in the dataset have the same size so it is not strictly necessary to Standardize or even Normalize the dataset, nevertheless I will normalize the images in order to converge faster during training and improve generalization. I won´t standardize it.\n",
        "\n",
        "In addition the images have a size of 255*255 which is quite standard and suitable for the models I am going to fit so I won´t rescale the images.\n",
        "\n",
        "### Data Augmentation\n",
        "As stated in the EDA anlaysis the main problem in the dataset is the imbalance of data amount presented in each category. In order to deal with this issue I will use the method of data augmentation to artificially incraese the number of images in the categories with less images.\n",
        "\n",
        "Is important to be carefull with this method, since it can provoke overfitting. To start with I will use the following technique with each variable:\n",
        "\n",
        "- apple_scab: Apply mild to moderate augmentation. An increase of 20-50% in the number of images will be the starting point.\n",
        "\n",
        "- black_rot: Will also apply mild to moderate augmentation. An increase of 20-50% in the number of images will be the starting point.\n",
        "\n",
        "- cedar_apple_rust: Apply moderate to aggressive data augmentation to this class to increase the number of samples. I aim to at least double the number of images in this class\n",
        "\n",
        "- healthy: No augmentation will be applied for now.\n",
        "\n",
        "### Splitting ratios\n",
        "- Train: 70%\n",
        "- Validation: 15%\n",
        "- Test: 15%\n",
        "\n",
        "### Parameters definition\n",
        "\n",
        "- IMAGE_WIDTH = 255\n",
        "- IMAGE_HEIGHT = 255\n",
        "- NUM_CHANNELS = 3\n",
        "- BATCH_SIZE = 32\n",
        "- EPOCHS = 50"
      ],
      "metadata": {
        "id": "G3pw1VH-3Onk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Class"
      ],
      "metadata": {
        "id": "pdHkkvHDhg0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class preprocessingClass:\n",
        "  def __init__(self):\n",
        "    self.IMAGE_HEIGHT = 255\n",
        "    self.IMAGE_WIDTH = 255\n",
        "    self.NUM_CHANNELS = 3\n",
        "    self.BATCH_SIZE = 32\n",
        "    self.EPOCHS = 50\n",
        "    self.CHANNELS = 3\n",
        "\n",
        "  def preprocessing(self, directory):\n",
        "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    shuffle = True,\n",
        "    image_size = (self.IMAGE_HEIGHT,self.IMAGE_WIDTH),\n",
        "    batch_size = self.BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def split_dataset(self, directory, train_split=0.7, val_split=0.15, test_split=0.15, shuffle = True, shuffle_size = 10000):\n",
        "    dataset = self.preprocessing(directory)\n",
        "    num_samples = len(dataset)\n",
        "\n",
        "    if shuffle:\n",
        "      dataset = dataset.shuffle(shuffle_size, seed = 12)\n",
        "\n",
        "    train_size = int(train_split * num_samples)\n",
        "    val_size = int(val_split * num_samples)\n",
        "    test_size = int(test_split * num_samples)\n",
        "\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size).take(val_size)\n",
        "    test_dataset = dataset.skip(train_size + val_size).take(test_size)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "  def train_gen(self,train_ds,rescaling_size):\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale = 1./rescaling_size,\n",
        "        horizontal_flip = True,\n",
        "        rotation_range = 10\n",
        "    )\n",
        "\n",
        "    tain_generator = train_datagen.flow_from_directory(\n",
        "        \"data/train\",\n",
        "        target_size = (self.IMAGE_WIDTH, self.IMAGE_HEIGHT),\n",
        "        batch_size = self.BATCH_SIZE,\n",
        "        class_mode = \"sparse\",\n",
        "        save_to_dir = \"AugmentedImages\"\n",
        "    )\n",
        "\n",
        "  def optimization(self,train_ds, val_ds, test_ds):\n",
        "    train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "    val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "    test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "  def dataAugmentation(self, train_ds):\n",
        "    data_augmentation_sequential = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "    ])\n",
        "\n",
        "    train_ds = train_ds.map(lambda x, y: (data_augmentation_sequential(x, training=True), y)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    return train_ds\n",
        "\n",
        "  def ResizeRescale(self, train_ds, val_ds, test_ds):\n",
        "    resize_rescale_sequential = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(self.IMAGE_WIDTH, self.IMAGE_HEIGHT),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "    ])\n",
        "\n",
        "    train_ds = train_ds.map(lambda x, y: (resize_rescale_sequential(x), y))\n",
        "    val_ds = val_ds.map(lambda x, y: (resize_rescale_sequential(x), y))\n",
        "    test_ds = test_ds.map(lambda x, y: (resize_rescale_sequential(x), y))\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "Lip2KYSDdEZN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessMethod = preprocessingClass()\n",
        "directory = \"/content/drive/MyDrive/Apple disease proyect/dataset\"\n",
        "\n",
        "# 1. Process the dataset -----------------------------------------------------------------------------------------------------------------\n",
        "preprocessMethod.preprocessing(directory)\n",
        "\n",
        "# 2. Split the dataset -------------------------------------------------------------------------------------------------------------------\n",
        "train_ds, val_ds, test_ds = preprocessMethod.split_dataset(directory, train_split = 0.7, val_split = 0.15, test_split = 0.15,\n",
        "                                                             shuffle = True, shuffle_size = 10000)\n",
        "# 3. Optimize the dataset ----------------------------------------------------------------------------------------------------------------\n",
        "preprocessMethod.optimization(train_ds, val_ds, test_ds)\n",
        "\n",
        "# 4. Data Augmentation --------------------------------------------------------------------------------------------------------------------\n",
        "train_ds = preprocessMethod.dataAugmentation(train_ds)\n",
        "\n",
        "# 5. Resizing and Rescaling ---------------------------------------------------------------------------------------------------------------\n",
        "train_ds, val_ds, test_ds = preprocessMethod.ResizeRescale(train_ds, val_ds, test_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7dibhDcLAvk",
        "outputId": "ae09182f-155e-446a-a53a-6dc2611bff01"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3171 files belonging to 4 classes.\n",
            "Found 3171 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "48i2VHlshbTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_HEIGHT = 255\n",
        "IMAGE_WIDTH = 255\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "CHANNELS = 3\n",
        "\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, CHANNELS)\n",
        "n_classes = 4\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "TK0VuiRif7C3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLev9NUqgXxm",
        "outputId": "c60e5b6e-b4a9-4f42-b527-b9e2d8bb8425"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 253, 253, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPooli  (None, 126, 126, 32)      0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 124, 124, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPooli  (None, 62, 62, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPooli  (None, 30, 30, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 28, 28, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPooli  (None, 14, 14, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPooli  (None, 6, 6, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPooli  (None, 2, 2, 64)          0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183812 (718.02 KB)\n",
            "Trainable params: 183812 (718.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "6Xs3ERT-gh5A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "qOy-oU5ihpBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=50,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "fwzr9XaQjucZ",
        "outputId": "4151cc82-e507-4759-8f3b-12541e7f0409"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 6/70 [=>............................] - ETA: 4:37 - loss: 1.2750 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2ed193659f6e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "n7uHkp6hgrU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataAugmentation():\n",
        "\n",
        "  def shuffleBatchCategory(self,category):\n",
        "      shuffled_dataset = random.sample(category, len(category))\n",
        "\n",
        "      return shuffled_dataset\n",
        "\n",
        "  def transformations(self, image_path):\n",
        "      image = tf.io.read_file(image_path)\n",
        "      image = tf.image.decode_image(image, channels=3)\n",
        "\n",
        "      image = tf.image.random_flip_left_right(image)\n",
        "      image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "      # Add the transoformations here\n",
        "\n",
        "      return image\n",
        "\n",
        "  def augmentation(self,image_list, num_image=None):\n",
        "      if num_image is None:\n",
        "          num_image = len(image_list)\n",
        "\n",
        "      augmented_images = [self.transformations(image) for image in image_list]\n",
        "      combined_images = image_list + augmented_images\n",
        "\n",
        "      return combined_images\n",
        "\n",
        "  def save_images(self, image_list, output_dir):\n",
        "      os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "      for i, image in enumerate(image_list):\n",
        "          transformed_filename = f\"transformed_image_{i}.jpg\"            # Genera un nombre de archivo único con sufijo de transformación y extensión .jpg\n",
        "          file_path = os.path.join(output_dir, transformed_filename)\n",
        "\n",
        "          image = tf.cast(image, tf.uint8)                               # Convierte la imagen a formato uint8 (0-255) y la guarda como JPEG\n",
        "          encoded_image = tf.image.encode_jpeg(image)\n",
        "\n",
        "          with open(file_path, \"wb\") as f:                               # Escribe el archivo JPEG en el directorio de salida\n",
        "              f.write(encoded_image.numpy())\n",
        "\n",
        "  def concatenate(category1, category2, category3):\n",
        "      general_dataset = category1 + category2 + category3\n",
        "\n",
        "      return general_dataset\n"
      ],
      "metadata": {
        "id": "8Kx3p1EYw-zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataAugmentor = DataAugmentation()\n",
        "\n",
        "# Apple_scab_augmentation----------------------------------------------------------------------------------------------------------------------------------\n",
        "shuffled_dataset_apple_scab = DataAugmentor.shuffleBatchCategory(category = apple_scab)\n",
        "\n",
        "augmented_dataset_apple_scab = DataAugmentor.augmentation(image_list = shuffled_dataset_apple_scab,num_image = round(len(shuffled_dataset_apple_scab)/2))\n",
        "\n",
        "DataAugmentor.save_images(image_list = augmented_dataset_apple_scab,\n",
        "                          output_dir =\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Apple_scab\" )\n",
        "\n",
        "# Black_rot augmentation----------------------------------------------------------------------------------------------------------------------------------\n",
        "shuffled_dataset_black_rot = DataAugmentor.shuffleBatchCategory(category = black_rot)\n",
        "\n",
        "augmented_dataset_black_rot = DataAugmentor.augmentation(image_list = shuffled_dataset_black_rot, num_image = round(len(shuffled_dataset_black_rot)/2))\n",
        "\n",
        "DataAugmentor.save_images(image_list = augmented_dataset_black_rot,\n",
        "                         output_dir =\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Black_rot\" )\n",
        "\n",
        "# Cedar_apple_rust augmentation---------------------------------------------------------------------------------------------------------------------------\n",
        "shuffled_dataset_cedar_apple_rust = DataAugmentor.shuffleBatchCategory(category = cedar_apple_rust)\n",
        "\n",
        "augmented_dataset_cedar_apple_rust = DataAugmentor.augmentation(image_list = shuffled_dataset_cedar_apple_rust)\n",
        "\n",
        "DataAugmentor.save_images(image_list = augmented_dataset_cedar_apple_rust,\n",
        "                          output_dir =\"/content/drive/MyDrive/Apple disease proyect/dataset/Apple___Cedar_apple_rust\" )"
      ],
      "metadata": {
        "id": "hRX8eHShAm4T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}